[[sec_serverless]]
== Serverless architecture

Serverless Architecture あるいは Serverless Computing とは， 従来とは全くアプローチの異なるクラウドシステムの設計方法である．
歴史的には， AWS が2014年に発表した https://aws.amazon.com/lambda/[Lamba] がサーバーレスアーキテクチャの先駆けとされている．
その後， Google や Microsoft などのクラウドプラットフォームも同様の機能の提供を開始している．
サーバーレスアーキテクチャの利点は，スケーラブルなクラウドシステムを安価かつ簡易に作成できる点であり，近年いたるところで導入が進んでいる．

Serverless とは，文字どおりの意味としてはサーバーなしで計算をするということになるが，それは一体どういう意味だろうか？
サーバーレスについて説明するためには，まずは従来的な， "serverful" とよばれるようなシステムについて解説しなければならない．

[[chap_serverful_cloud]]
=== Serverful クラウド (従来型)

従来的なクラウドシステムのスケッチを <<serverful>> に示す．
クライアントから送信されたリクエストは，最初に API サーバーに送られる．
API サーバーでは，リクエストの内容に応じてタスクが実行される．
タスクには，APIサーバーだけで完結できるものもあるが，多くの場合，データベースの読み書きが必要である．
データベースには，データベース専用の独立したサーバーマシンが用いられることが一般的である．
また，画像や動画などの容量の大きいデータは，また別のストレージサーバーに保存されることが多い．
これらの APIサーバー，データベースサーバー，ストレージサーバーはそれぞれ独立したサーバーマシンであり， AWS の言葉では EC2 による仮想インスタンスを想定してもらったらよい．

多くのウェブサービスでは，多数のクライアントからのリクエストを処理するため，複数のサーバーマシンがクラウド内で起動し，負荷を分散するような設計がなされている．
クライアントから来たリクエストを計算容量に余裕のあるサーバーに振り分けるような操作を **Load balancing** とよび，そのような操作を担当するマシンのことを **Load balancer** という． 

計算負荷を分散する目的で多数のインスタンスを起動するのはよいのだが，計算負荷が小さすぎてアイドリング状態にあるようではコストと電力の無駄遣いである．
したがって，すべてのサーバーが常に目標とする計算負荷を維持するよう，計算の負荷に応じてクラスター内の仮想サーバーの数を動的に増減させるような仕組みが必要である．
そのような仕組みを**クラスターのスケーリング**とよび，負荷の増大に応答して新しい仮想インスタンスをクラスターに追加する操作を **scale-out**，負荷の減少に応答してインスタンスをシャットダウンする操作を **scale-in** とよぶ．
クラスターのスケーリングは，各インスタンスを監視・統括するような一つ階層が上のサーバーを配置することで自動的に実行されるような設計がなされる．
クラスターのスケーリングは， API サーバーではもちろんのこと，データベースサーバー・ストレージサーバーでも必要になる．
**クラウドシステム内すべての箇所で，負荷が均一になるような調整が必要なのである．**

[[serverful]]
.Serverful なクラウドシステム
image::imgs/serverful.png[serverful, 700, align="center"]

=== Serverless クラウドへ

上述したように，従来のクラウドシステムの設計で非常に重要なのが，クラスターのスケーリングである．
コストパフォーマンスを最大化するには，各サーバーの稼働率を100%に近づけるようなスケーリングのパラメータの調整が必要である．
しかしながら，クラスターのスケーリングの最適化はかなり手間のかかる作業である．

さらに問題を複雑にするのは，APIサーバーで処理されるべきタスクが，非一様な点である．
非一様であるとは，たとえばタスクAは3000ミリ秒の実行時間と 512MB のメモリーを消費し，別のタスクBは1000ミリ秒の実行時間と 128MB のメモリーを消費する，というような状況を差している．
一つのサーバーマシンが計算負荷が異なる複数のタスクを処理する場合，クラスターのスケーリングはより複雑になる．
この状況をシンプルにするために，１サーバーで実行するタスクは１種類に限る，という設計も可能であるが，そうするとで生まれる弊害も多い (ほとんど使われないタスクに対してもサーバー一台をまるまる割り当てなければならない = ほとんどアイドリング状態になってしまう，など)．

もっとシンプルで見通しのよいクラウドシステムのスケーリングの仕組みはないだろうか？

従来の serverful なシステムでの最大の問題点は，**サーバーをまるまる占有してしまう**という点にある．
すなわち， EC2 インスタンスを起動したとき，そのインスタンスは起動したユーザーだけが使えるものであり，**計算のリソース (CPUやRAM) が独占的に割り当てられた状態**になる．
固定した計算資源の割り当てがされてしまっているので，**インスタンスの計算負荷が0%であろうが100%であろうが，均一の使用料金が起動時間に比例**して発生する．

サーバーレスアーキテクチャは，このような **独占的に割り当てられた計算リソースというものを完全に廃止する．**
サーバーレスアーキテクチャでは，計算のリソースは，クラウドプロバイダーがすべて管理する．
クライアントは，仮想インスタンスを一台まるごと借りるのではなく，**実行したいプログラムをクラウドに提出する**．
クラウドプロバイダーは，自身のもつ巨大な計算リソースから空きを探し，提出されたプログラムを実行し，実行結果をクライアントに返す．
以上を図示すると， <<serverless>> のようになる．

[[serverless]]
.従来のクラウドと Serverless クラウドの比較
image::imgs/serverless.png[serverless, 700, align="center"]

サーバーレスクラウドを利用することで，**クラウドのコストは実際に使用した計算の総量 (稼働時間) で決定される**ことになる．
これは，計算の実行総量に関わらずインスタンスの起動時間で料金が決定されていた従来のシステムと比べて大きな違いである．
一方で，クライアントが同時に大量のタスクを送信した場合でも，クラウドプロバイダー側はその需要に応えることのできるような計算リソースを瞬時に割り当てることができるので，非常に高いスケーラビリティを実現できる．
以降では，実際にクラウドを動かしながら，サーバーレスをより具体的に体験していこう．

[NOTE]
====
従来型の(仮想インスタンスをたくさん起動するような)クラウドシステムは，**賃貸**と似ているかもしれない．
部屋を借りるというのは，その部屋でどれだけの時間を過ごそうが，月々の家賃は一定である．
同様に，仮想サーバーも，それがどれほどの計算を行っているかに関わらず，一定の料金が時間ごとに発生する．

一方で，サーバーレスクラウドは，**電気・水道・ガス料金** と似ている．
こちらは，実際に使用した量に比例して料金が決定されている．
サーバーレスクラウドも，実際に計算を行った総時間で料金が決まる仕組みになっている．
====

=== Lambda

image:imgs/aws_logos/Lambda.png[Lambda, 100]

AWS でサーバーレスコンピューティングの中心を担うのが， https://aws.amazon.com/lambda/[Lambda] である．

Lambda の使い方を <<lambda_workflow>> に図示している．
Lambda の仕組みはシンプルで，まずユーザーは実行したいプログラムのコードを事前に登録しておく．
プログラムは， Python, Node.js, ruby などの主要な言語がサポートされている．
そして，プログラムを実行したいときに，そのプログラムを実行 (invoke) するコマンドを Lambda に送信する．
Lambda では， invoke のリクエストを受け取るとただちに (数ミリセカンドから数百ミリセカンド程度の時間で) プログラムの実行を開始する．
そして，実行結果をクライアントやその他の計算機に返す．

[[lambda_workflow]]
.AWS Lambda
image::imgs/lambda_workflow.png[lambda_workflow, 500, align="center"]

このように，Lambda では占有された仮想インスタンスは存在せず，実行を待っているプログラムだけがある状態である．
invoke のリクエストに応じて，プログラムが AWS の巨大な計算機プールのどこかに配置され，実行される．
同時に複数のリクエストが来た場合でも， AWS はそれらを実行するための計算リソースを割り当て，並列的に処理を行ってくれる．
原理上は，**数千から数万のリクエストが同時に来たとしても， Lambda はそれらを同時に実行することができる**．
このような，占有された仮想サーバーの存在なしに，動的に関数を実行するサービスのことを総称して **FaaS (Function as a Service)** とよばれることがある．

Lambda では 128MB から 10240MB のメモリーを使用することができる (執筆時点)．
また，実効的な CPU の容量はメモリーの量に比例する形で割り当てられる
(しかし， RAM と CPU 容量の具体的な換算表は AWS からは公開されていない)．
実行時間は100ミリ秒の単位で記録され，実行時間に比例して料金が決定される．
<<lambda_pricing>> は Lambda の利用料金の利用料金表である．

[[lambda_pricing]]
[cols="1,1", options="header"] 
.Lambda の料金表
|===
|Memory (MB)
|Price per 100ms

|128
|$0.0000002083

|512
|$0.0000008333

|1024
|$0.0000016667

|3008
|$0.0000048958
|===

たとえば， 128MB のメモリーを使用する関数を，それぞれ200ミリ秒，合計で100万回実行した場合，
0.0000002083 * 2 * 10^6 = **$0.4** の料金となる．
ウェブサーバーのデータベースの更新など簡単な計算であれば，200ミリ秒程度で実行できる関数も多いことから，100万回データベースの更新を行ったとしても，たった $0.4 しかコストが発生しないことになる．

=== サーバーレスストレージ: S3

image:imgs/aws_logos/S3.png[S3, 100]

サーバーレスの概念は，ストレージにも拡張されている．

従来的なストレージ (ファイルシステム) では，必ずホストとなるマシンと OS が存在しなければならない．
したがって，それほどパワーは必要ないまでも，ある程度の CPU リソースを割かなければならない．
また，従来的なファイルシステムでは，データ領域のサイズは最初にディスクを初期化するときに決めなければならず，後から容量を増加させることはしばしば困難である
(ZFS などのファイルシステムを使えばある程度は自由にファイルシステムのサイズを変更することは可能である)．
よって，従来的なクラウドでは，ストレージを借りる際にはあらかじめディスクのサイズを指定せねばならず，ディスクの中身が空であろうと満杯であろうと，同じ利用料金が発生することになる (<<fig:s3_vs_filesystem>>)．

https://aws.amazon.com/s3/[Simple Storage Service (S3)] は，サーバーレスなストレージシステムを提供する (<<fig:s3_vs_filesystem>>)．
S3 は従来的なストレージシステムと異なり， OS に"マウントする”という概念はない．
基本的に API を通じてデータの読み書きの操作が行われる．
また，データの冗長化やバックアップなど，通常ならば OS と CPU が介在しなければならない操作も， API を通じて行うことができる．
S3 では事前に決められたディスク領域のサイズはなく，データを入れれば入れた分だけ，保存領域は拡大していく
(仕様上はペタバイトスケールのデータを保存することが可能である)．
ストレージにかかる料金は，保存してあるデータの総容量で決定される．

[[fig:s3_vs_filesystem]]
.S3 と従来的なファイルシステムの比較
image::imgs/s3_vs_filesystem.png[s3_vs_filesystem, 700, align="center"]

S3 の料金は，保存してあるデータの総容量と，外部へのデータ転送の総量で決定される (https://aws.amazon.com/s3/pricing/?nc=sn&loc=4[参考])．
執筆時点では，データの保存には $0.025 per GB per month のコストが発生する．
したがって，1000GB のデータを S3 に一ヵ月保存した場合， $25 の料金が発生することになる．
また， S3 はデータを外に取り出す際の通信にもコストが発生する．
執筆時点では，S3 からインターネットを通じて外部にデータを転送すると $0.114 per GB のコストが発生する．
データを S3 に入れる (data-in) 通信は無料で行える．
また， AWS の 同じ Region 内のサービス (Lambda など) にデータを転送するのは無料である．
AWS の Region をまたいだデータの転送には， $0.09 per GB のコストが発生する．

=== サーバーレスデータベース: DynamoDB

image:imgs/aws_logos/DynamoDB.png[S3, 100]

サーバーレスの概念は，データベースにも適用することができる．

ここでいうデータベースとは， Web サービスなどにおけるユーザーや商品の情報を記録しておくための保存領域のことを指している．
従来的に有名なデータベースとしては
https://www.mysql.com/[MySQL],
https://www.postgresql.org/[PostgreSQL],
https://www.mongodb.com/[MongoDB]
などが挙げられる．
データベースと普通のストレージの違いは，データの検索機能にある．
普通のストレージではデータは単純にディスクに書き込まれるだけだが，
データベースでは検索がより効率的になるようなデータの配置がされたり，
頻繁にアクセスされるデータはメモリーにキャッシュされるなどの機能が備わっている．
これにより，巨大なデータの中から，興味のある要素を高速に取得することができる．

このような検索機能を実現するには，当然 CPU の存在が必須である．
したがって，従来的なデータベースを構築する際は，ストレージ領域に加えて，たくさんの CPU コアを搭載したマシンが用いられることが多い．
また，データベースが巨大な場合は複数マシンにまたがった分散型のシステムが設計される．
分散型システムの場合は， <<chap_serverful_cloud>> で議論したようにデータベースへのアクセス負荷に応じて適切なスケーリングがなされる必要がある．

https://aws.amazon.com/dynamodb/[DynamoDB] は， AWS が提供しているサーバーレスな分散型データベースである．
サーバーレスであるので，占有されたデータベース用仮想インスタンスは存在せず， API を通じてデータの書き込み・読み出し・検索などの操作を行う．
S3 と同様に，データ保存領域の上限は定められておらず，データを入れれば入れた分だけ，保存領域は拡大していく．
また，データベースへの負荷が増減したときのスケーリングは， DynamoDB が自動で行うので，ユーザーは心配する必要はない．

DynamoDB での利用料金の計算はやや複雑なのだが， "On-demand Capacity" というモードで使用した場合，
100万回の write request units (データの書き込み操作) で $1.25, 100万回の read request units (データの読み込み操作) で $0.25 の料金がかかる．
また，保存されたデータ容量に対して $0.25 per GB per month のコストが発生する．

=== その他のサーバーレスクラウドの構成要素

以上で紹介した Lambda, S3, DynamoDB がサーバーレスクラウドの中で最も使用する頻度が高いサービスになる．
その他のサーバーレスクラウドの構成要素を以下に列挙する．

* https://aws.amazon.com/api-gateway/[API Gateway]: API を構築する際のルーティングを担う．
<<sec_bashoutter>> で簡単に取り上げる．
* https://aws.amazon.com/fargate/[Fargate]: <<sec_fargate_qabot>> で触れた Fargate も，サーバーレスクラウドの要素の一部である．
Lambda との違いは，Lambda よりも大容量のメモリーや CPU を要するような計算などを行うことができる点が挙げられる．
* https://aws.amazon.com/sns/[Simple Notification Service (SNS)]: サーバーレスのサービス間でイベントをやり取りするためのサービス．
* https://aws.amazon.com/step-functions/[Step Functions]: サーバーレスのサービス間のオーケストレーションを担う．

[TIP]
====
**サーバーレスアーキテクチャは万能か？**

この問への答えは，筆者は NO であると考える．

ここまで，サーバーレスの利点を強調して説明をしてきたが，まだまだ新しい技術なだけに，欠点，あるいはサーバーフルなシステムに劣る点は数多くある．

大きな欠点を一つあげるとすれば，サーバーレスのシステムは各クラウドプラットフォームに固有なものなので，特定のプラットフォームでしか運用できないシステムになってしまう点であろう．
AWS で作成したサーバーレスのシステムを， Google のクラウドに移植するには，かなり大掛かりなプログラムの書き換えが必要になる．
一方， serverful なシステムであれば，プラットフォーム間のマイグレーションは比較的簡単に行うことができる．
クラウドプロバイダーとしては，自社のシステムへの依存度を強めることで，顧客を離さないようにするという狙いがあるのだろう...

その他，サーバーレスコンピューティングの欠点や今後の課題などは，次の論文で詳しく議論されている．
興味のある読者はぜひ読んでいただきたい．

* https://arxiv.org/abs/1812.03651[Hellerstein et al., "Serverless Computing: One Step Forward, Two Steps Back" arXiv (2018)]
====

