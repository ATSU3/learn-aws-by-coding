[[sec_aws_batch]]
== Hands-on #3: AWS Batch を使って機械学習を並列化する

ハンズオン第三回では，クラウド上に複数の仮想マシンからなるクラスターを作成し，前章で学んだ Docker を使って並列計算を実行する方法を紹介する．
具体的には，深層学習におけるハイパーパラメータ最適化を取り上げる．
ハイパーパラメータとは，勾配降下法によって最適化されるニューラルネットのパラメータの外にあるパラメータのことであり，具体的にはモデルの層の幅・深さなどネットワークのアーキテクチャに関わるもの，学習率やモメンタムなどパラメータの更新則に関わるものなどが含まる．
深層学習においてハイパーパラメータの調整はとても重要なタスクである．
しかしながら，ハイパーパラメータを調整するには，少しづつ条件を変えながら何度もニューラルネットを学習させる必要があり，多くの計算時間がかかる．
本ハンズオンでは，クラウドの強力な計算リソースを利用することで並列的にニューラルネットの訓練を実行することでこの問題を高速に解く方法を学んでいこう．

=== Auto scaling groups (ASG)

ハンズオンに入っていく前に， **Auto scaling groups (ASG)** と呼ばれる EC2 の概念を知っておく必要がある．

ECS の概要を示した <<ecs_overview>> をもう一度見てみよう．
この図で， ECS と連動しているクラスターが示されているが，このクラスターの中で計算を行う実体としては，**EC2 と Fargate のいずれか** (あるいは両者のハイブリッド) を選択することができる．
Fargate について次章 (<<sec_fargate_qabot>>) にて詳しく説明する．
クラスターの計算環境として EC2 が選択された場合，タスクの投入とともに EC2 インスタンスが起動し，計算が実行される．
EC2 クラスターには **Auto scaling groups (ASG)** と呼ばれるクラスターのスケーリングを担うサービスが配置されており， ASG によってインスタンスの起動・停止が行われる．
ASG にはユーザーの指定したスケーリングのポリシーを定義することが可能である．
例えば，クラスター全体の稼働率を 80% に維持する，かつ，起動インスタンスの上限は100台とする，などのポリシーを設定できる．
あるいはユーザーの作成したカスタムのプログラムでスケーリングを制御することも可能である．
ECS と ASG が協調することで，フレキシブルかつ効率的なタスクの配置とクラスターのスケーリングが可能になるのである．

=== AWS Batch

上記で説明したように， ECS と ASG を組み合わせることで，所望の計算システムを構築することが可能である．
しかしながら， ECS と ASG にはかなり込み入った設定が必要であり，初心者にとっても経験者にとってもなかなか面倒なプログラミングが要求される．
そこで， ECS と ASG によるクラスターの設計を自動化してくれるサービスが提供されている．
それが **AWS Batch** である．

AWS Batch はその名の通りバッチ (Batch) 化されたジョブ (それ一つで完結し，他のジョブとの相互的な情報のやり取りがないような計算) を想定している．
バッチ計算には，例えば多くの科学計算や機械学習が当てはまる．
AWS Batch を用いることの利点は，クラスターのスケーリングやジョブの割り振りはすべて自動で実行され，ユーザーは背後のクラウドの詳細を気にすることなく，大量のジョブを投入することのできるシステムが手に入る点である．

AWS Batch では，ジョブの投入・管理をスムーズに行うため，次のような概念が設定されている (<<>>)．
まず， Job というのが，AWS Batch の中での計算タスクの最小単位


Job Definitions とは，ジョブの内容を定義するものであり，これには実行されるべき Docker のイメージのアドレスや，割り当てる CPU・RAM の容量，環境変数などの設定が含まれる．
ユーザーがジョブを投入すると，それは Job Queues に入る．
Job queues とは，実行されるのを待っているジョブの待ち列のことであり，時間的に最も先頭に投入されたジョブが最初に実行される．
**Compute environment** とは，先述したクラスターとほぼ同義の概念であり，計算が実際に実行される場所 (EC2 や Fargate からなるクラスター) を指す．
Job queues に溜まったジョブは， Compute environment にそのジョブを受け付ける余裕がある場合に，その Compute environment に投下される．

以上が AWS Batch を使用する上で理解しておかなければならない概念であるが，くどくど言葉で説明してもなかなかピンとこないだろう．
ここからは，実際に自分で手を動かしながら学んでいこう．

=== 準備

本ハンズオンの実行には，第一回ハンズオンで説明した準備 (<<handson_01_prep>>) が整っていることを前提とする．
それ以外に必要な準備はない．

=== MNIST 手書き文字認識 (再訪)

今回のハンズオンでは，機械学習のハイパーパラメータ調整を取り上げると冒頭で述べた．
その最もシンプルな例題として， <<sec_handson02>> で扱った MNIST 手書き文字認識の問題を再度取り上げよう．
<<sec_handson02>> では，適当にチョイスしたハイパーパラメータを用いてモデルの訓練を行った．
ここで使用したプログラムの中でのハイパーパラメータの例として，確率的勾配降下法 (SGD) における学習率やモメンタムが含まれる．
コードでいうと，以下の行が該当する．

[source, python]
----
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
----

ここで，使用された 学習率 (`lr=0.01`) や モメンタム (`momentum=0.5`) は恣意的に選択された値であり，これがベストな数値であるのかはわからない．
たまたまこのチョイスが最適であるかもしれないし，もっと高い精度を出すハイパーパラメータの組が存在するかもしれない．
この問題に答えるため，ハイパーパラメータサーチを行おう．
今回は，最もシンプルなアプローチとして，**グリッドサーチ**によるハイパーパラメータサーチを行おう．

.ハイパーパラメータの最適化について
****
機械学習のハイパーパラメータの最適化には大きく３つのアプローチが挙げられる．
グリッドサーチ法，ランダムサーチ法，そしてベイズ最適化による方法である．

グリッドサーチ法とは，ハイパーパラメータの組をある範囲の中で可能な組み合わせをすべて計算し，最適なパラメータの組を見出す方法である．
最もシンプルかつ確実な方法であるが，すべての組み合わせの可能性を愚直に計算するのには大きな計算コストがかかる．

ランダムサーチ法とは，ハイパーパラメータの組をある範囲の中でランダムに抽出し，大量に試行されたランダムな組の中から最適なパラメータの組を見出す方法である．
すべての可能性を網羅的に探索できるわけではないが，調整すべきパラメータの数が多数ある場合に，グリッドサーチよりも効率的に広い探索空間をカバーすることができる．

ベイズ最適化を用いた方法では，過去の探索結果から次にどの組み合わせを探索すべきかという指標を計算し，次に探索するパラメータを決定する．
これによりグリッドサーチやランダムサーチよりも少ない試行回数で最適なパラメータにたどり着くことができる．

並列化の観点でいうと，グリッドサーチとランダムサーチは各ハイパーパラメータの組の計算は独立に実行することができるため並列化が容易である．
このように独立したジョブとして分割・並列化可能な問題を Embarrassingly parallel な問題と呼ぶ (直訳すると"恥ずかしいほど並列化可能な問題"，ということになる)．
Embarrassingly parallel な問題はクラウドの強力な計算リソースを用いることで，非常なシンプルな実装で解くことができる．
この章ではこのようなタイプの並列計算を取り上げる．

一方，ベイズ最適化による方法は，過去の結果をもとに次の探索が決定されるので，並列化はそれほど単純ではない．
最近では https://optuna.org/[optuna] などのハイパーパラメータ探索のためのライブラリが発達しており，ベイズ最適化の数理的な処理を自動で実行してくれるので便利である．
これらのライブラリを使うと，もし一台のコンピュータ(ノード)の中に複数の GPU が存在する場合は，並列に計算を実行することができる．
しかしながら，一台のノードにとどまらず，複数のノードをまたいだ並列化は，高度なプログラミングテクニックが必要とされるだけでなく，ノード間の接続様式などクラウドのアーキテクチャにも深く依存するものである．
本書ではここまで高度なクラウドの使用方法までは立ち入らない．
****

