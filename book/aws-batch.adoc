== Hands-on #3: AWS Batch を使って機械学習を並列化する

ハンズオン第三回では，クラウド上に複数の仮想マシンからなるクラスターを作成し，前章で学んだ Docker を使って並列計算を実行する方法を紹介する．
具体的には，深層学習におけるハイパーパラメータ最適化を行う．
ハイパーパラメータとは，勾配降下法によって最適化されるニューラルネットのパラメータの外にあるパラメータのことであり，具体的にはモデルの層の幅・深さなどネットワークのアーキテクチャに関わるもの，学習率やモメンタムなどパラメータの更新則に関わるものなどが含まる．
深層学習においてハイパーパラメータの調整はとても重要なタスクである．
しかしながら，ハイパーパラメータを調整するには，少しづつ条件を変えながら何度もニューラルネットを学習させる必要があり，計算に時間がかかる．
本ハンズオンでは，クラウドの強力な計算リソースを利用することでこの問題を高速に解く方法を学んでいく．

.ハイパーパラメータの最適化について
****
機械学習のハイパーパラメータの最適化には大きく３つのアプローチが挙げられる．
グリッドサーチ法，ランダムサーチ法，そしてベイズ最適化による方法である．

グリッドサーチ法とは，ハイパーパラメータの組をある範囲の中で可能な組み合わせをすべて計算し，最適なパラメータの組を見出す方法である．
最もシンプルかつ確実な方法であるが，すべての組み合わせの可能性を愚直に計算するのには大きな計算コストがかかる．

ランダムサーチ法とは，ハイパーパラメータの組をある範囲の中でランダムに抽出し，大量に試行されたランダムな組の中から最適なパラメータの組を見出す方法である．
すべての可能性を網羅的に探索できるわけではないが，特に調整すべきパラメータの数が多数ある場合に，グリッドサーチよりも効率的に広い探索空間をカバーすることができる．

ベイズ最適化を用いた方法では，過去の探索結果から次にどの組み合わせを探索すべきかという指標を計算し，次に探索するパラメータを決定する．
よってグリッドサーチやランダムサーチよりも少ない試行回数で最適なパラメータにたどり着くことができる．

並列化の観点でいうと，グリッドサーチとランダムサーチは各ハイパーパラメータの組の計算は独立に実行することができるため並列化が容易である．
このように独立したジョブとして分割・並列化可能な問題を Embarrassingly parallel な問題と呼ぶ．
Embarrassingly parallel な問題はクラウドの強力な計算リソースを用いることで，非常なシンプルな実装で解くことができる．
この章ではこのようなタイプの並列計算を取り上げる．

一方，ベイズ最適化による方法は，過去の結果をもとに次の探索が決定されるので，並列化はそれほど単純ではない．
最近では https://optuna.org/[optuna] などのハイパーパラメータ探索のためのライブラリが発達しており，ベイズ最適化の数理的な処理を自動で実行してくれるので便利である．
これらのライブラリは，もし一台のコンピュータ(ノード)の中に複数の GPU が存在する場合は，並列に計算を実行することができる．
しかしながら，複数のノードをまたいだ並列化は，かなり高度なプログラミングテクニックが必要とされるだけでなく，ノード間の接続様式などクラウドのアーキテクチャにも深く依存するものである．
本書ではここまで高度なクラウドの使用方法までは立ち入らない．
****

=== AWS Batch

